# test_chunking.py
from agents.smart_chunker import SmartChunkerAgent
from docx import Document
import traceback
import nltk
nltk.download('punkt_tab')

def test_chunking():
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞–Ω–∫–µ—Ä–∞...")
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–ø–æ—Ä—Ç
    try:
        chunker = SmartChunkerAgent("all-MiniLM-L6-v2")
        print("‚úÖ –ß–∞–Ω–∫–µ—Ä —Å–æ–∑–¥–∞–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–µ—Ä–∞: {e}")
        traceback.print_exc()
        return
    
    # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—Ä–æ—Å—Ç–æ–º —Ç–µ–∫—Å—Ç–µ
    test_text = "–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç. –û–Ω —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏."
    
    try:
        chunks = chunker.split_by_semantics(test_text)
        print(f"‚úÖ –ß–∞–Ω–∫–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç. –ü–æ–ª—É—á–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
        for i, chunk in enumerate(chunks):
            print(f"   –ß–∞–Ω–∫ {i+1}: {chunk[:50]}...")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á–∞–Ω–∫–æ–≤–∞–Ω–∏—è: {e}")
        traceback.print_exc()
    
    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
    try:
        doc = Document(r"docmind-rag\uploads\–ê–Ω–∞–ª–∏–∑ –æ—Ç –ù–µ–π—Ä–æ–Ω–∞–Ω–∞–ª–∏—Ç–∏–∫–∞.docx")
        print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –æ—Ç–∫—Ä—ã—Ç. –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {len(doc.paragraphs)}")
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞
        sample_text = "\n".join([p.text for p in doc.paragraphs[:10] if p.text.strip()])
        chunks = chunker.split_by_semantics(sample_text)
        print(f"‚úÖ –ß–∞–Ω–∫–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç. –ß–∞–Ω–∫–æ–≤: {len(chunks)}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å –¥–æ–∫—É–º–µ–Ω—Ç–æ–º: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    test_chunking()