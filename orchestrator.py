# orchestrator.py
import os
import json
import yaml
from typing import List, Dict, Any, Optional

# –ò–º–ø–æ—Ä—Ç—ã –∞–≥–µ–Ω—Ç–æ–≤
from agents.doc_parser import DocParserAgent
from agents.smart_chunker import SmartChunkerAgent
from agents.vector_agent import VectorAgent
from agents.answer_gpt import AnswerGPTAgent
from agents.validator import ValidatorAgent

class RAGOrchestrator:
    """–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω–æ–π RAG —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, config_path: str = "config.yaml"):
        print(f"üîÑ RAGOrchestrator.__init__({config_path})")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        print(f"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {self.config['embedding_model']}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤
        print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤...")
        self.agents = {}
        
        try:
            self.agents['parser'] = DocParserAgent()
            print("  ‚úÖ ParserAgent")
        except Exception as e:
            print(f"  ‚ùå ParserAgent: {e}")
        
        try:
            self.agents['chunker'] = SmartChunkerAgent(
                embedding_model=self.config['embedding_model'],
                chunk_size=self.config['chunk_size'],
                overlap=self.config['overlap_size']
            )
            print("  ‚úÖ ChunkerAgent")
        except Exception as e:
            print(f"  ‚ùå ChunkerAgent: {e}")
        
        try:
            self.agents['vector'] = VectorAgent(
                embedding_model=self.config['embedding_model'],
                use_gpu=self.config['use_gpu'],
                batch_size=self.config['batch_size'],
                db_path=self.config['vector_db_path']
            )
            print("  ‚úÖ VectorAgent")
        except Exception as e:
            print(f"  ‚ùå VectorAgent: {e}")
        
        try:
            self.agents['generator'] = AnswerGPTAgent(
                api_base=self.config['lm_studio_url'],
                model=self.config['generation_model'],
                temperature=self.config['temperature'],
                max_tokens=self.config['max_tokens']
            )
            print("  ‚úÖ GeneratorAgent")
        except Exception as e:
            print(f"  ‚ùå GeneratorAgent: {e}")
        
        try:
            self.agents['validator'] = ValidatorAgent()
            print("  ‚úÖ ValidatorAgent")
        except Exception as e:
            print(f"  ‚ùå ValidatorAgent: {e}")
        
        self.doc_structure = None
        self.is_indexed = False
        print("‚úÖ RAGOrchestrator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def process_document(self, docx_path: str) -> Dict[str, Any]:
        """
        –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        print(f"\nüìÑ –ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {docx_path}")
        
        try:
            # 1. –ü–ê–†–°–ò–ù–ì - –∏–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            print("üîç –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã...")
            self.doc_structure = self.agents['parser'].parse_with_hierarchy(docx_path)
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤: {len(self.doc_structure['chapters'])}")
            
            # 2. –ß–ê–ù–ö–û–í–ê–ù–ò–ï - —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–º—ã—Å–ª–æ–≤—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
            print("‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞–Ω–∫–∏...")
            chunks = []
            metadata = []
            
            for chapter_idx, chapter in enumerate(self.doc_structure['chapters']):
                print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–ª–∞–≤—ã {chapter_idx + 1}: {chapter['title'][:50]}...")
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –≥–ª–∞–≤—ã
                if chapter.get('content'):
                    print(f"    –ö–æ–Ω—Ç–µ–Ω—Ç –≥–ª–∞–≤—ã: {len(chapter['content'])} —Å–∏–º–≤–æ–ª–æ–≤")
                    chapter_chunks = self.agents['chunker'].split_by_semantics(chapter['content'])
                    print(f"    –ü–æ–ª—É—á–µ–Ω–æ —á–∞–Ω–∫–æ–≤ –∏–∑ –≥–ª–∞–≤—ã: {len(chapter_chunks)}")
                    
                    for chunk in chapter_chunks:
                        chunks.append(chunk)
                        metadata.append({
                            'chapter_id': chapter['id'],
                            'chapter_title': chapter['title'],
                            'level': 1,
                            'type': 'chapter'
                        })
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–¥–µ–ª–æ–≤ –≤–Ω—É—Ç—Ä–∏ –≥–ª–∞–≤—ã
                for section_idx, section in enumerate(chapter.get('sections', [])):
                    print(f"    –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–¥–µ–ª–∞ {section_idx + 1}: {section['title'][:50]}...")
                    
                    if section.get('content'):
                        section_chunks = self.agents['chunker'].split_by_semantics(section['content'])
                        print(f"      –ü–æ–ª—É—á–µ–Ω–æ —á–∞–Ω–∫–æ–≤ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞: {len(section_chunks)}")
                        
                        for chunk in section_chunks:
                            chunks.append(chunk)
                            metadata.append({
                                'chapter_id': chapter['id'],
                                'chapter_title': chapter['title'],
                                'section_id': section['id'],
                                'section_title': section['title'],
                                'level': 2,
                                'type': 'section'
                            })
            
            print(f"üìä –í—Å–µ–≥–æ —Å–æ–±—Ä–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç—ã–µ —á–∞–Ω–∫–∏
            if len(chunks) == 0:
                print("‚ö†Ô∏è –í–Ω–∏–º–∞–Ω–∏–µ: –Ω–µ —Å–æ–∑–¥–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞!")
                # –°–æ–∑–¥–∞–µ–º –æ–¥–∏–Ω –æ–±—â–∏–π —á–∞–Ω–∫
                all_text = ""
                for chapter in self.doc_structure['chapters']:
                    if chapter.get('content'):
                        all_text += chapter['content'] + "\n"
                
                if all_text:
                    chunks = [all_text[:self.config['chunk_size']]]
                    metadata = [{
                        'chapter_id': 'all',
                        'chapter_title': '–í–µ—Å—å –¥–æ–∫—É–º–µ–Ω—Ç',
                        'level': 0,
                        'type': 'full'
                    }]
                    print(f"‚úÖ –°–æ–∑–¥–∞–Ω –æ–¥–∏–Ω –æ–±—â–∏–π —á–∞–Ω–∫")
            
            # 3. –ò–ù–î–ï–ö–°–ê–¶–ò–Ø - —Å–æ–∑–¥–∞–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏–Ω–¥–µ–∫—Å
            print("üîó –°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞...")
            self.agents['vector'].create_index(chunks, metadata)
            self.is_indexed = True
            
            print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω. –ì–ª–∞–≤: {len(self.doc_structure['chapters'])}, –ß–∞–Ω–∫–æ–≤: {len(chunks)}")
            
            return {
                'structure': self.doc_structure,
                'chunks_count': len(chunks),
                'chapters_count': len(self.doc_structure['chapters'])
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def query_document(self, question: str, chapter_filter: Optional[str] = None) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {question}")
        
        if not self.is_indexed:
            return {
                "error": "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç",
                "answer": "–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç."
            }
        
        try:
            # 1. –ü–û–ò–°–ö - –Ω–∞—Ö–æ–¥–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —á–∞–Ω–∫–∏
            print("üîé –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤...")
            filters = {"chapter_id": chapter_filter} if chapter_filter else None
            chunks = self.agents['vector'].hierarchical_search(question, top_k=5, filters=filters)
            print(f"   –ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
            
            if not chunks:
                return {
                    "answer": "–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ.",
                    "sources": [],
                    "confidence": 0,
                    "warnings": ["–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"]
                }
            
            # 2. –ì–ï–ù–ï–†–ê–¶–ò–Ø - —Å–æ–∑–¥–∞–µ–º –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
            print("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
            answer = self.agents['generator'].generate_answer(question, chunks)
            
            # 3. –í–ê–õ–ò–î–ê–¶–ò–Ø - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–∞
            print("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
            validated = self.agents['validator'].validate(answer, chunks)
            
            return validated
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            import traceback
            traceback.print_exc()
            return {
                "error": str(e),
                "answer": f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}",
                "sources": [],
                "confidence": 0
            }
    
    def get_document_structure(self) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        return self.doc_structure
    
    def get_status(self) -> Dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ —Å–∏—Å—Ç–µ–º—ã
        """
        return {
            "is_indexed": self.is_indexed,
            "has_structure": self.doc_structure is not None,
            "chapters_count": len(self.doc_structure['chapters']) if self.doc_structure else 0,
            "agents": list(self.agents.keys())
        }