# agents/simple_chunker.py (–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–º–µ–Ω–∞)
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import nltk
from typing import List, Dict, Any

nltk.download('punkt', quiet=True)

class SimpleChunkerAgent:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π —á–∞–Ω–∫–µ—Ä –±–µ–∑ —Å–µ–º–∞–Ω—Ç–∏–∫–∏ - –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    
    def __init__(self, embedding_model=None, chunk_size=500, overlap=50):
        self.chunk_size = chunk_size
        self.overlap = overlap
        print("üì¶ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è SIMPLE —á–∞–Ω–∫–µ—Ä (–±–µ–∑ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤)")
    
    def split_by_semantics(self, text: str) -> List[str]:
        """–ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ä–∞–∑–º–µ—Ä—É"""
        if not text:
            return []
        
        words = text.split()
        chunks = []
        current_chunk = []
        current_size = 0
        
        for word in words:
            word_size = len(word) + 1  # +1 –¥–ª—è –ø—Ä–æ–±–µ–ª–∞
            
            if current_size + word_size > self.chunk_size and current_chunk:
                chunks.append(' '.join(current_chunk))
                
                # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
                overlap_words = current_chunk[-self.overlap//10:] if self.overlap > 0 else []
                current_chunk = overlap_words
                current_size = sum(len(w) + 1 for w in overlap_words)
            
            current_chunk.append(word)
            current_size += word_size
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        print(f"‚úÖ Simple —á–∞–Ω–∫–µ—Ä —Å–æ–∑–¥–∞–ª {len(chunks)} —á–∞–Ω–∫–æ–≤")
        return chunks